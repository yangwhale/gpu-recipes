Epoch 0:   7% 1/15 [00:35<08:16, 35.49s/it, v_num=None, reduced_train_loss=11.20, global_step=0.000, consumed_samples=2048.0, train_step_timing in s=35.50]DLL 2025-03-21 09:36:05.977509 - 0 reduced_train_loss : 11.166093826293945  lr : 0.0  global_step : 0.0  consumed_samples : 2048.0  train_backward_timing in s : 4.410743713378906e-05  grad_norm : 56.531246185302734  train_step_timing in s : 35.49093055725098  epoch : 0 
Epoch 0:  13% 2/15 [01:05<07:03, 32.55s/it, v_num=None, reduced_train_loss=11.20, global_step=1.000, consumed_samples=4096.0, train_step_timing in s=32.60]DLL 2025-03-21 09:36:35.592637 - 1 reduced_train_loss : 11.16601276397705  lr : 7.500000265281415e-08  global_step : 1.0  consumed_samples : 4096.0  train_backward_timing in s : 4.100799560546875e-05  grad_norm : 56.523284912109375  train_step_timing in s : 32.551326513290405  epoch : 0 
Epoch 0:  20% 3/15 [01:34<06:18, 31.57s/it, v_num=None, reduced_train_loss=11.20, global_step=2.000, consumed_samples=6144.0, train_step_timing in s=31.60]DLL 2025-03-21 09:37:05.184367 - 2 reduced_train_loss : 11.155923843383789  lr : 1.500000053056283e-07  global_step : 2.0  consumed_samples : 6144.0  train_backward_timing in s : 4.363059997558594e-05  grad_norm : 56.53178024291992  train_step_timing in s : 31.563714186350506  epoch : 0 
Epoch 0:  27% 4/15 [02:04<05:41, 31.06s/it, v_num=None, reduced_train_loss=11.10, global_step=3.000, consumed_samples=8192.0, train_step_timing in s=31.10]DLL 2025-03-21 09:37:34.730542 - 3 reduced_train_loss : 11.116107940673828  lr : 2.2499999374758772e-07  global_step : 3.0  consumed_samples : 8192.0  train_backward_timing in s : 4.553794860839844e-05  grad_norm : 56.507301330566406  train_step_timing in s : 31.05845421552658  epoch : 0 
Epoch 0:  33% 5/15 [02:33<05:07, 30.75s/it, v_num=None, reduced_train_loss=11.00, global_step=4.000, consumed_samples=10240.0, train_step_timing in s=30.70]DLL 2025-03-21 09:38:04.245938 - 4 reduced_train_loss : 10.96586799621582  lr : 3.000000106112566e-07  global_step : 4.0  consumed_samples : 10240.0  train_backward_timing in s : 4.7540664672851564e-05  grad_norm : 56.633155822753906  train_step_timing in s : 30.74916787147522  epoch : 0 
Epoch 0:  40% 6/15 [03:03<04:35, 30.56s/it, v_num=None, reduced_train_loss=10.40, global_step=5.000, consumed_samples=12288.0, train_step_timing in s=29.60]DLL 2025-03-21 09:38:33.840562 - 5 reduced_train_loss : 10.425722122192383  lr : 3.7500001326407073e-07  global_step : 5.0  consumed_samples : 12288.0  train_backward_timing in s : 4.677772521972656e-05  grad_norm : 56.882450103759766  train_step_timing in s : 29.569313526153564  epoch : 0 
Epoch 0:  47% 7/15 [03:32<04:03, 30.42s/it, v_num=None, reduced_train_loss=8.970, global_step=6.000, consumed_samples=14336.0, train_step_timing in s=29.60]DLL 2025-03-21 09:39:03.406586 - 6 reduced_train_loss : 8.969529151916504  lr : 4.4999998749517545e-07  global_step : 6.0  consumed_samples : 14336.0  train_backward_timing in s : 4.9686431884765626e-05  grad_norm : 58.675010681152344  train_step_timing in s : 29.559554433822633  epoch : 0 
Epoch 0:  53% 8/15 [04:02<03:32, 30.31s/it, v_num=None, reduced_train_loss=8.380, global_step=7.000, consumed_samples=16384.0, train_step_timing in s=29.60]DLL 2025-03-21 09:39:32.955174 - 7 reduced_train_loss : 8.384511947631836  lr : 5.25000018569699e-07  global_step : 7.0  consumed_samples : 16384.0  train_backward_timing in s : 4.749298095703125e-05  grad_norm : 60.279632568359375  train_step_timing in s : 29.55091733932495  epoch : 0 
Epoch 0:  60% 9/15 [04:32<03:01, 30.23s/it, v_num=None, reduced_train_loss=4.960, global_step=8.000, consumed_samples=18432.0, train_step_timing in s=29.60]DLL 2025-03-21 09:40:02.528476 - 8 reduced_train_loss : 4.963380813598633  lr : 6.000000212225132e-07  global_step : 8.0  consumed_samples : 18432.0  train_backward_timing in s : 4.596710205078125e-05  grad_norm : 68.78748321533203  train_step_timing in s : 29.556352853775024  epoch : 0 
Epoch 0:  67% 10/15 [05:01<02:30, 30.16s/it, v_num=None, reduced_train_loss=4.200, global_step=9.000, consumed_samples=20480.0, train_step_timing in s=29.60]DLL 2025-03-21 09:40:32.078174 - 9 reduced_train_loss : 4.204579830169678  lr : 6.750000238753273e-07  global_step : 9.0  consumed_samples : 20480.0  train_backward_timing in s : 4.415512084960937e-05  grad_norm : 54.9891242980957  train_step_timing in s : 29.5632285118103  epoch : 0 
Epoch 0:  73% 11/15 [05:31<02:00, 30.11s/it, v_num=None, reduced_train_loss=3.120, global_step=10.00, consumed_samples=22528.0, train_step_timing in s=29.60]DLL 2025-03-21 09:41:01.667107 - 10 reduced_train_loss : 3.117267608642578  lr : 7.500000265281415e-07  global_step : 10.0  consumed_samples : 22528.0  train_backward_timing in s : 4.477500915527344e-05  grad_norm : 39.55404281616211  train_step_timing in s : 29.56200852394104  epoch : 0 
Epoch 0:  80% 12/15 [06:00<01:30, 30.06s/it, v_num=None, reduced_train_loss=1.850, global_step=11.00, consumed_samples=24576.0, train_step_timing in s=29.50]DLL 2025-03-21 09:41:31.152121 - 11 reduced_train_loss : 1.8521578311920166  lr : 8.249999723375367e-07  global_step : 11.0  consumed_samples : 24576.0  train_backward_timing in s : 4.258155822753906e-05  grad_norm : 22.9488468170166  train_step_timing in s : 29.545771884918214  epoch : 0 
Epoch 0:  87% 13/15 [06:30<01:00, 30.01s/it, v_num=None, reduced_train_loss=1.440, global_step=12.00, consumed_samples=26624.0, train_step_timing in s=29.50]DLL 2025-03-21 09:42:00.606668 - 12 reduced_train_loss : 1.4390486478805542  lr : 8.999999749903509e-07  global_step : 12.0  consumed_samples : 26624.0  train_backward_timing in s : 4.2486190795898435e-05  grad_norm : 15.399749755859375  train_step_timing in s : 29.526964378356933  epoch : 0 
Epoch 0:  93% 14/15 [06:59<00:29, 29.97s/it, v_num=None, reduced_train_loss=1.100, global_step=13.00, consumed_samples=28672.0, train_step_timing in s=29.50]DLL 2025-03-21 09:42:29.996860 - 13 reduced_train_loss : 1.0987637042999268  lr : 9.75000034486584e-07  global_step : 13.0  consumed_samples : 28672.0  train_backward_timing in s : 4.105567932128906e-05  grad_norm : 10.13785171508789  train_step_timing in s : 29.490446662902833  epoch : 0 
Epoch 0: 100% 15/15 [07:28<00:00, 29.93s/it, v_num=None, reduced_train_loss=0.832, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=29.50]DLL 2025-03-21 09:42:59.381020 - 14 reduced_train_loss : 0.8315519094467163  lr : 1.050000037139398e-06  global_step : 14.0  consumed_samples : 30720.0  train_backward_timing in s : 3.905296325683594e-05  grad_norm : 6.765076160430908  train_step_timing in s : 29.457420206069948  epoch : 0 
Epoch 0: 100% 15/15 [07:28<00:00, 29.93s/it, v_num=None, reduced_train_loss=0.832, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=29.50]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [07:28<00:00, 29.93s/it, v_num=None, reduced_train_loss=0.832, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=29.50]
[NeMo I 2025-03-21 09:42:59 nemo_logging:393] train_step_timing in s: [35.49, 32.55, 31.56, 31.06, 30.75, 29.57, 29.56, 29.55, 29.56, 29.56, 29.56, 29.55, 29.53, 29.49, 29.46]
[NeMo I 2025-03-21 09:42:59 nemo_logging:393] TFLOPs per sec per GPU=1068.36