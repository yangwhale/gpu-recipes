Epoch 0:   7% 1/15 [00:26<06:15, 26.81s/it, v_num=None, reduced_train_loss=11.20, global_step=0.000, consumed_samples=1024.0, train_step_timing in s=26.80]DLL 2025-03-21 07:22:37.947823 - 0 reduced_train_loss : 11.156208992004395  lr : 0.0  global_step : 0.0  consumed_samples : 1024.0  train_backward_timing in s : 5.078315734863281e-05  grad_norm : 40.07704162597656  train_step_timing in s : 26.810487270355225  epoch : 0 
Epoch 0:  13% 2/15 [00:37<04:01, 18.58s/it, v_num=None, reduced_train_loss=11.20, global_step=1.000, consumed_samples=2048.0, train_step_timing in s=18.60]DLL 2025-03-21 07:22:48.301631 - 1 reduced_train_loss : 11.156325340270996  lr : 7.500000265281415e-08  global_step : 1.0  consumed_samples : 2048.0  train_backward_timing in s : 4.839897155761719e-05  grad_norm : 44.188812255859375  train_step_timing in s : 18.58035445213318  epoch : 0 
Epoch 0:  20% 3/15 [00:47<03:10, 15.87s/it, v_num=None, reduced_train_loss=11.00, global_step=2.000, consumed_samples=3072.0, train_step_timing in s=15.90]DLL 2025-03-21 07:22:58.737374 - 2 reduced_train_loss : 11.022981643676758  lr : 1.500000053056283e-07  global_step : 2.0  consumed_samples : 3072.0  train_backward_timing in s : 5.5631001790364586e-05  grad_norm : 44.54487991333008  train_step_timing in s : 15.86433204015096  epoch : 0 
Epoch 0:  27% 4/15 [00:58<02:39, 14.51s/it, v_num=None, reduced_train_loss=10.70, global_step=3.000, consumed_samples=4096.0, train_step_timing in s=14.50]DLL 2025-03-21 07:23:09.163426 - 3 reduced_train_loss : 10.716750144958496  lr : 2.2499999374758772e-07  global_step : 3.0  consumed_samples : 4096.0  train_backward_timing in s : 5.3822994232177734e-05  grad_norm : 44.497764587402344  train_step_timing in s : 14.503936171531677  epoch : 0 
Epoch 0:  33% 5/15 [01:08<02:16, 13.70s/it, v_num=None, reduced_train_loss=10.30, global_step=4.000, consumed_samples=5120.0, train_step_timing in s=13.70]DLL 2025-03-21 07:23:19.616614 - 4 reduced_train_loss : 10.268534660339355  lr : 3.000000106112566e-07  global_step : 4.0  consumed_samples : 5120.0  train_backward_timing in s : 5.2642822265625e-05  grad_norm : 45.133182525634766  train_step_timing in s : 13.693109941482543  epoch : 0 
Epoch 0:  40% 6/15 [01:18<01:58, 13.15s/it, v_num=None, reduced_train_loss=9.650, global_step=5.000, consumed_samples=6144.0, train_step_timing in s=10.40]DLL 2025-03-21 07:23:30.058081 - 5 reduced_train_loss : 9.647109985351562  lr : 3.7500001326407073e-07  global_step : 5.0  consumed_samples : 6144.0  train_backward_timing in s : 5.2356719970703124e-05  grad_norm : 46.28175354003906  train_step_timing in s : 10.418671655654908  epoch : 0 
Epoch 0:  47% 7/15 [01:29<01:42, 12.77s/it, v_num=None, reduced_train_loss=8.940, global_step=6.000, consumed_samples=7168.0, train_step_timing in s=10.40]DLL 2025-03-21 07:23:40.559638 - 6 reduced_train_loss : 8.94218921661377  lr : 4.4999998749517545e-07  global_step : 6.0  consumed_samples : 7168.0  train_backward_timing in s : 5.2976608276367185e-05  grad_norm : 47.433841705322266  train_step_timing in s : 10.44826169013977  epoch : 0 
Epoch 0:  53% 8/15 [01:39<01:27, 12.48s/it, v_num=None, reduced_train_loss=7.980, global_step=7.000, consumed_samples=8192.0, train_step_timing in s=10.50]DLL 2025-03-21 07:23:51.012527 - 7 reduced_train_loss : 7.978696823120117  lr : 5.25000018569699e-07  global_step : 7.0  consumed_samples : 8192.0  train_backward_timing in s : 4.69207763671875e-05  grad_norm : 49.61509323120117  train_step_timing in s : 10.451774501800537  epoch : 0 
Epoch 0:  60% 9/15 [01:50<01:13, 12.26s/it, v_num=None, reduced_train_loss=6.960, global_step=8.000, consumed_samples=9216.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:01.460252 - 8 reduced_train_loss : 6.957085609436035  lr : 6.000000212225132e-07  global_step : 8.0  consumed_samples : 9216.0  train_backward_timing in s : 4.7159194946289065e-05  grad_norm : 51.82065200805664  train_step_timing in s : 10.456138181686402  epoch : 0 
Epoch 0:  67% 10/15 [02:00<01:00, 12.08s/it, v_num=None, reduced_train_loss=5.670, global_step=9.000, consumed_samples=10240.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:11.886366 - 9 reduced_train_loss : 5.6661248207092285  lr : 6.750000238753273e-07  global_step : 9.0  consumed_samples : 10240.0  train_backward_timing in s : 4.8160552978515625e-05  grad_norm : 51.255149841308594  train_step_timing in s : 10.45079026222229  epoch : 0 
Epoch 0:  73% 11/15 [02:11<00:47, 11.94s/it, v_num=None, reduced_train_loss=4.520, global_step=10.00, consumed_samples=11264.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:22.466883 - 10 reduced_train_loss : 4.524024963378906  lr : 7.500000265281415e-07  global_step : 10.0  consumed_samples : 11264.0  train_backward_timing in s : 4.668235778808594e-05  grad_norm : 44.659324645996094  train_step_timing in s : 10.478638124465942  epoch : 0 
Epoch 0:  80% 12/15 [02:21<00:35, 11.82s/it, v_num=None, reduced_train_loss=3.440, global_step=11.00, consumed_samples=12288.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:32.920698 - 11 reduced_train_loss : 3.4440295696258545  lr : 8.249999723375367e-07  global_step : 11.0  consumed_samples : 12288.0  train_backward_timing in s : 4.668235778808594e-05  grad_norm : 34.91311264038086  train_step_timing in s : 10.469112157821655  epoch : 0 
Epoch 0:  87% 13/15 [02:32<00:23, 11.71s/it, v_num=None, reduced_train_loss=2.570, global_step=12.00, consumed_samples=13312.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:43.358771 - 12 reduced_train_loss : 2.573309898376465  lr : 8.999999749903509e-07  global_step : 12.0  consumed_samples : 13312.0  train_backward_timing in s : 4.8160552978515625e-05  grad_norm : 26.878965377807617  train_step_timing in s : 10.466079139709473  epoch : 0 
Epoch 0:  93% 14/15 [02:42<00:11, 11.62s/it, v_num=None, reduced_train_loss=1.960, global_step=13.00, consumed_samples=14336.0, train_step_timing in s=10.50]DLL 2025-03-21 07:24:53.793649 - 13 reduced_train_loss : 1.9555457830429077  lr : 9.75000034486584e-07  global_step : 13.0  consumed_samples : 14336.0  train_backward_timing in s : 4.8112869262695315e-05  grad_norm : 19.418838500976562  train_step_timing in s : 10.46348009109497  epoch : 0 
Epoch 0: 100% 15/15 [02:53<00:00, 11.54s/it, v_num=None, reduced_train_loss=1.530, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=10.50]DLL 2025-03-21 07:25:04.164096 - 14 reduced_train_loss : 1.5334961414337158  lr : 1.050000037139398e-06  global_step : 14.0  consumed_samples : 15360.0  train_backward_timing in s : 4.6205520629882815e-05  grad_norm : 13.879148483276367  train_step_timing in s : 10.452366352081299  epoch : 0 
Epoch 0: 100% 15/15 [02:53<00:00, 11.54s/it, v_num=None, reduced_train_loss=1.530, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=10.50]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [02:53<00:00, 11.54s/it, v_num=None, reduced_train_loss=1.530, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=10.50]
[NeMo I 2025-03-21 07:25:04 nemo_logging:393] train_step_timing in s: [26.81, 18.58, 15.86, 14.5, 13.69, 10.42, 10.45, 10.45, 10.46, 10.45, 10.48, 10.47, 10.47, 10.46, 10.45]
[NeMo I 2025-03-21 07:25:04 nemo_logging:393] TFLOPs per sec per GPU=1508.01