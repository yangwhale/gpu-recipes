Epoch 0:   7% 1/15 [00:36<08:31, 36.57s/it, v_num=None, reduced_train_loss=11.20, global_step=0.000, consumed_samples=2048.0, train_step_timing in s=36.60]DLL 2025-03-21 09:05:00.776933 - 0 reduced_train_loss : 11.156713485717773  lr : 0.0  global_step : 0.0  consumed_samples : 2048.0  train_backward_timing in s : 3.814697265625e-05  grad_norm : 41.95968246459961  train_step_timing in s : 36.56730937957764  epoch : 0 
Epoch 0:  13% 2/15 [00:56<06:07, 28.27s/it, v_num=None, reduced_train_loss=11.20, global_step=1.000, consumed_samples=4096.0, train_step_timing in s=28.30]DLL 2025-03-21 09:05:20.745787 - 1 reduced_train_loss : 11.156681060791016  lr : 7.500000265281415e-08  global_step : 1.0  consumed_samples : 4096.0  train_backward_timing in s : 3.8623809814453125e-05  grad_norm : 43.96891403198242  train_step_timing in s : 28.266439199447632  epoch : 0 
Epoch 0:  20% 3/15 [01:16<05:06, 25.56s/it, v_num=None, reduced_train_loss=11.00, global_step=2.000, consumed_samples=6144.0, train_step_timing in s=25.60]DLL 2025-03-21 09:05:40.889146 - 2 reduced_train_loss : 11.022157669067383  lr : 1.500000053056283e-07  global_step : 2.0  consumed_samples : 6144.0  train_backward_timing in s : 4.275639851888021e-05  grad_norm : 44.56336975097656  train_step_timing in s : 25.55768672625224  epoch : 0 
Epoch 0:  27% 4/15 [01:36<04:26, 24.22s/it, v_num=None, reduced_train_loss=10.70, global_step=3.000, consumed_samples=8192.0, train_step_timing in s=24.20]DLL 2025-03-21 09:06:01.091834 - 3 reduced_train_loss : 10.713507652282715  lr : 2.2499999374758772e-07  global_step : 3.0  consumed_samples : 8192.0  train_backward_timing in s : 4.190206527709961e-05  grad_norm : 44.57912826538086  train_step_timing in s : 24.21807485818863  epoch : 0 
Epoch 0:  33% 5/15 [01:57<03:54, 23.43s/it, v_num=None, reduced_train_loss=10.30, global_step=4.000, consumed_samples=10240.0, train_step_timing in s=23.40]DLL 2025-03-21 09:06:21.341018 - 4 reduced_train_loss : 10.265257835388184  lr : 3.000000106112566e-07  global_step : 4.0  consumed_samples : 10240.0  train_backward_timing in s : 4.3725967407226564e-05  grad_norm : 45.07495880126953  train_step_timing in s : 23.42371597290039  epoch : 0 
Epoch 0:  40% 6/15 [02:17<03:26, 22.90s/it, v_num=None, reduced_train_loss=9.650, global_step=5.000, consumed_samples=12288.0, train_step_timing in s=20.20]DLL 2025-03-21 09:06:41.598170 - 5 reduced_train_loss : 9.646905899047852  lr : 3.7500001326407073e-07  global_step : 5.0  consumed_samples : 12288.0  train_backward_timing in s : 4.410743713378906e-05  grad_norm : 45.8884162902832  train_step_timing in s : 20.16108012199402  epoch : 0 
Epoch 0:  47% 7/15 [02:37<03:00, 22.52s/it, v_num=None, reduced_train_loss=8.940, global_step=6.000, consumed_samples=14336.0, train_step_timing in s=20.20]DLL 2025-03-21 09:07:01.860276 - 6 reduced_train_loss : 8.942376136779785  lr : 4.4999998749517545e-07  global_step : 6.0  consumed_samples : 14336.0  train_backward_timing in s : 4.520416259765625e-05  grad_norm : 47.12535858154297  train_step_timing in s : 20.219753408432005  epoch : 0 
Epoch 0:  53% 8/15 [02:57<02:35, 22.24s/it, v_num=None, reduced_train_loss=7.970, global_step=7.000, consumed_samples=16384.0, train_step_timing in s=20.20]DLL 2025-03-21 09:07:22.139389 - 7 reduced_train_loss : 7.9730329513549805  lr : 5.25000018569699e-07  global_step : 7.0  consumed_samples : 16384.0  train_backward_timing in s : 4.2819976806640624e-05  grad_norm : 49.050846099853516  train_step_timing in s : 20.24690890312195  epoch : 0 
Epoch 0:  60% 9/15 [03:18<02:12, 22.02s/it, v_num=None, reduced_train_loss=6.940, global_step=8.000, consumed_samples=18432.0, train_step_timing in s=20.30]DLL 2025-03-21 09:07:42.392902 - 8 reduced_train_loss : 6.938415050506592  lr : 6.000000212225132e-07  global_step : 8.0  consumed_samples : 18432.0  train_backward_timing in s : 4.482269287109375e-05  grad_norm : 51.290767669677734  train_step_timing in s : 20.25710391998291  epoch : 0 
Epoch 0:  67% 10/15 [03:38<01:49, 21.84s/it, v_num=None, reduced_train_loss=5.580, global_step=9.000, consumed_samples=20480.0, train_step_timing in s=20.30]DLL 2025-03-21 09:08:02.652716 - 9 reduced_train_loss : 5.58418083190918  lr : 6.750000238753273e-07  global_step : 9.0  consumed_samples : 20480.0  train_backward_timing in s : 4.324913024902344e-05  grad_norm : 50.678104400634766  train_step_timing in s : 20.259139585494996  epoch : 0 
Epoch 0:  73% 11/15 [03:58<01:26, 21.70s/it, v_num=None, reduced_train_loss=4.510, global_step=10.00, consumed_samples=22528.0, train_step_timing in s=20.30]DLL 2025-03-21 09:08:22.889171 - 10 reduced_train_loss : 4.505258560180664  lr : 7.500000265281415e-07  global_step : 10.0  consumed_samples : 22528.0  train_backward_timing in s : 4.510879516601562e-05  grad_norm : 43.47907638549805  train_step_timing in s : 20.254926109313963  epoch : 0 
Epoch 0:  80% 12/15 [04:18<01:04, 21.58s/it, v_num=None, reduced_train_loss=3.380, global_step=11.00, consumed_samples=24576.0, train_step_timing in s=20.30]DLL 2025-03-21 09:08:43.201910 - 11 reduced_train_loss : 3.3802459239959717  lr : 8.249999723375367e-07  global_step : 11.0  consumed_samples : 24576.0  train_backward_timing in s : 4.5013427734375e-05  grad_norm : 33.53722381591797  train_step_timing in s : 20.265046882629395  epoch : 0 
Epoch 0:  87% 13/15 [04:39<00:42, 21.48s/it, v_num=None, reduced_train_loss=2.560, global_step=12.00, consumed_samples=26624.0, train_step_timing in s=20.30]DLL 2025-03-21 09:09:03.488400 - 12 reduced_train_loss : 2.5581181049346924  lr : 8.999999749903509e-07  global_step : 12.0  consumed_samples : 26624.0  train_backward_timing in s : 4.730224609375e-05  grad_norm : 25.463666915893555  train_step_timing in s : 20.266501808166502  epoch : 0 
Epoch 0:  93% 14/15 [04:59<00:21, 21.39s/it, v_num=None, reduced_train_loss=1.950, global_step=13.00, consumed_samples=28672.0, train_step_timing in s=20.20]DLL 2025-03-21 09:09:23.651440 - 13 reduced_train_loss : 1.9513040781021118  lr : 9.75000034486584e-07  global_step : 13.0  consumed_samples : 28672.0  train_backward_timing in s : 4.553794860839844e-05  grad_norm : 18.529693603515625  train_step_timing in s : 20.248453426361085  epoch : 0 
Epoch 0: 100% 15/15 [05:19<00:00, 21.30s/it, v_num=None, reduced_train_loss=1.520, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=20.20]DLL 2025-03-21 09:09:43.713035 - 14 reduced_train_loss : 1.5190694332122803  lr : 1.050000037139398e-06  global_step : 14.0  consumed_samples : 30720.0  train_backward_timing in s : 4.6825408935546876e-05  grad_norm : 13.158127784729004  train_step_timing in s : 20.20891876220703  epoch : 0 
Epoch 0: 100% 15/15 [05:19<00:00, 21.30s/it, v_num=None, reduced_train_loss=1.520, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=20.20]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [05:19<00:00, 21.30s/it, v_num=None, reduced_train_loss=1.520, global_step=14.00, consumed_samples=30720.0, train_step_timing in s=20.20]
[NeMo I 2025-03-21 09:09:43 nemo_logging:393] train_step_timing in s: [36.57, 28.27, 25.56, 24.22, 23.42, 20.16, 20.22, 20.25, 20.26, 20.26, 20.25, 20.27, 20.27, 20.25, 20.21]
[NeMo I 2025-03-21 09:09:43 nemo_logging:393] TFLOPs per sec per GPU=1557.90