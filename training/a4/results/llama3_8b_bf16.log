Epoch 0:   7% 1/15 [00:32<07:34, 32.49s/it, v_num=None, reduced_train_loss=11.00, global_step=0.000, consumed_samples=1024.0, train_step_timing in s=32.50]DLL 2025-03-10 09:45:10.575801 - 0 reduced_train_loss : 11.031511306762695  lr : 1.9960080521741475e-07  global_step : 0.0  consumed_samples : 1024.0  train_backward_timing in s : 4.100799560546875e-05  grad_norm : 14.033583641052246  train_step_timing in s : 32.48634076118469  epoch : 0 
Epoch 0:  13% 2/15 [00:57<06:15, 28.88s/it, v_num=None, reduced_train_loss=11.00, global_step=0.000, consumed_samples=1024.0, train_Epoch 0:  13% 2/15 [00:57<06:15, 28.88s/it, v_num=None, reduced_train_loss=11.00, global_step=1.000, consumed_samples=2048.0, train_step_timing in s=28.90]DLL 2025-03-10 09:45:35.856731 - 1 reduced_train_loss : 11.028753280639648  lr : 3.992016104348295e-07  global_step : 1.0  consumed_samples : 2048.0  train_backward_timing in s : 4.6253204345703125e-05  grad_norm : 14.055694580078125  train_step_timing in s : 28.882083892822266  epoch : 0 
Epoch 0:  20% 3/15 [01:23<05:32, 27.75s/it, v_num=None, reduced_train_loss=11.00, global_step=1.000, consumed_samples=2048.0, train_Epoch 0:  20% 3/15 [01:23<05:32, 27.75s/it, v_num=None, reduced_train_loss=11.00, global_step=2.000, consumed_samples=3072.0, train_step_timing in s=27.70]DLL 2025-03-10 09:46:01.329091 - 2 reduced_train_loss : 10.994549751281738  lr : 5.988023872305348e-07  global_step : 2.0  consumed_samples : 3072.0  train_backward_timing in s : 4.38690185546875e-05  grad_norm : 13.996115684509277  train_step_timing in s : 27.744494994481403  epoch : 0 
Epoch 0:  27% 4/15 [01:48<04:59, 27.19s/it, v_num=None, reduced_train_loss=11.00, global_step=2.000, consumed_samples=3072.0, train_Epoch 0:  27% 4/15 [01:48<04:59, 27.19s/it, v_num=None, reduced_train_loss=10.90, global_step=3.000, consumed_samples=4096.0, train_step_timing in s=27.20]DLL 2025-03-10 09:46:26.843819 - 3 reduced_train_loss : 10.889408111572266  lr : 7.98403220869659e-07  global_step : 3.0  consumed_samples : 4096.0  train_backward_timing in s : 4.2557716369628906e-05  grad_norm : 13.95335865020752  train_step_timing in s : 27.186276733875275  epoch : 0 
Epoch 0:  33% 5/15 [02:14<04:28, 26.86s/it, v_num=None, reduced_train_loss=10.90, global_step=3.000, consumed_samples=4096.0, train_Epoch 0:  33% 5/15 [02:14<04:28, 26.86s/it, v_num=None, reduced_train_loss=10.60, global_step=4.000, consumed_samples=5120.0, train_step_timing in s=26.90]DLL 2025-03-10 09:46:52.389216 - 4 reduced_train_loss : 10.55019760131836  lr : 9.980039976653643e-07  global_step : 4.0  consumed_samples : 5120.0  train_backward_timing in s : 4.224777221679687e-05  grad_norm : 14.38469409942627  train_step_timing in s : 26.85750823020935  epoch : 0 
Epoch 0:  40% 6/15 [02:39<03:59, 26.65s/it, v_num=None, reduced_train_loss=10.60, global_step=4.000, consumed_samples=5120.0, train_Epoch 0:  40% 6/15 [02:39<03:59, 26.65s/it, v_num=None, reduced_train_loss=10.40, global_step=5.000, consumed_samples=6144.0, train_step_timing in s=25.50]DLL 2025-03-10 09:47:17.971526 - 5 reduced_train_loss : 10.400927543640137  lr : 1.1976047744610696e-06  global_step : 5.0  consumed_samples : 6144.0  train_backward_timing in s : 4.286766052246094e-05  grad_norm : 14.788304328918457  train_step_timing in s : 25.476048135757445  epoch : 0 
Epoch 0:  47% 7/15 [03:05<03:32, 26.50s/it, v_num=None, reduced_train_loss=10.40, global_step=5.000, consumed_samples=6144.0, train_Epoch 0:  47% 7/15 [03:05<03:32, 26.50s/it, v_num=None, reduced_train_loss=9.610, global_step=6.000, consumed_samples=7168.0, train_step_timing in s=25.50]DLL 2025-03-10 09:47:43.593179 - 6 reduced_train_loss : 9.613393783569336  lr : 1.397205551256775e-06  global_step : 6.0  consumed_samples : 7168.0  train_backward_timing in s : 4.1484832763671875e-05  grad_norm : 17.64301300048828  train_step_timing in s : 25.544181871414185  epoch : 0 
Epoch 0:  53% 8/15 [03:31<03:04, 26.39s/it, v_num=None, reduced_train_loss=9.610, global_step=6.000, consumed_samples=7168.0, train_Epoch 0:  53% 8/15 [03:31<03:04, 26.39s/it, v_num=None, reduced_train_loss=9.400, global_step=7.000, consumed_samples=8192.0, train_step_timing in s=25.60]DLL 2025-03-10 09:48:09.198536 - 7 reduced_train_loss : 9.395454406738281  lr : 1.596806441739318e-06  global_step : 7.0  consumed_samples : 8192.0  train_backward_timing in s : 4.1151046752929686e-05  grad_norm : 18.576942443847656  train_step_timing in s : 25.570748329162598  epoch : 0 
Epoch 0:  60% 9/15 [03:56<02:37, 26.30s/it, v_num=None, reduced_train_loss=9.400, global_step=7.000, consumed_samples=8192.0, train_Epoch 0:  60% 9/15 [03:56<02:37, 26.30s/it, v_num=None, reduced_train_loss=8.880, global_step=8.000, consumed_samples=9216.0, train_step_timing in s=25.60]DLL 2025-03-10 09:48:34.795339 - 8 reduced_train_loss : 8.884027481079102  lr : 1.7964072185350233e-06  global_step : 8.0  consumed_samples : 9216.0  train_backward_timing in s : 4.329681396484375e-05  grad_norm : 20.129133224487305  train_step_timing in s : 25.587138414382935  epoch : 0 
Epoch 0:  67% 10/15 [04:22<02:11, 26.23s/it, v_num=None, reduced_train_loss=8.880, global_step=8.000, consumed_samples=9216.0, trainEpoch 0:  67% 10/15 [04:22<02:11, 26.23s/it, v_num=None, reduced_train_loss=7.940, global_step=9.000, consumed_samples=10240.0, train_step_timing in s=25.60]DLL 2025-03-10 09:49:00.416609 - 9 reduced_train_loss : 7.942157745361328  lr : 1.9960079953307286e-06  global_step : 9.0  consumed_samples : 10240.0  train_backward_timing in s : 4.482269287109375e-05  grad_norm : 22.398273468017578  train_step_timing in s : 25.602261590957642  epoch : 0 
Epoch 0:  73% 11/15 [04:47<01:44, 26.18s/it, v_num=None, reduced_train_loss=7.940, global_step=9.000, consumed_samples=10240.0, traiEpoch 0:  73% 11/15 [04:47<01:44, 26.18s/it, v_num=None, reduced_train_loss=7.270, global_step=10.00, consumed_samples=11264.0, train_step_timing in s=25.60]DLL 2025-03-10 09:49:26.030921 - 10 reduced_train_loss : 7.269984245300293  lr : 2.1956088858132716e-06  global_step : 10.0  consumed_samples : 11264.0  train_backward_timing in s : 4.5680999755859374e-05  grad_norm : 23.39780044555664  train_step_timing in s : 25.608668756484985  epoch : 0 
Epoch 0:  80% 12/15 [05:13<01:18, 26.13s/it, v_num=None, reduced_train_loss=7.270, global_step=10.00, consumed_samples=11264.0, traiEpoch 0:  80% 12/15 [05:13<01:18, 26.13s/it, v_num=None, reduced_train_loss=6.200, global_step=11.00, consumed_samples=12288.0, train_step_timing in s=25.60]DLL 2025-03-10 09:49:51.646058 - 11 reduced_train_loss : 6.201907634735107  lr : 2.3952095489221392e-06  global_step : 11.0  consumed_samples : 12288.0  train_backward_timing in s : 4.4918060302734376e-05  grad_norm : 26.311471939086914  train_step_timing in s : 25.607405805587767  epoch : 0 
Epoch 0:  87% 13/15 [05:39<00:52, 26.09s/it, v_num=None, reduced_train_loss=6.200, global_step=11.00, consumed_samples=12288.0, traiEpoch 0:  87% 13/15 [05:39<00:52, 26.09s/it, v_num=None, reduced_train_loss=5.200, global_step=12.00, consumed_samples=13312.0, train_step_timing in s=25.60]DLL 2025-03-10 09:50:17.232329 - 12 reduced_train_loss : 5.20228385925293  lr : 2.5948104394046823e-06  global_step : 12.0  consumed_samples : 13312.0  train_backward_timing in s : 4.506111145019531e-05  grad_norm : 26.981470108032227  train_step_timing in s : 25.603681516647338  epoch : 0 
Epoch 0:  93% 14/15 [06:04<00:26, 26.05s/it, v_num=None, reduced_train_loss=5.200, global_step=12.00, consumed_samples=13312.0, traiEpoch 0:  93% 14/15 [06:04<00:26, 26.05s/it, v_num=None, reduced_train_loss=4.210, global_step=13.00, consumed_samples=14336.0, train_step_timing in s=25.60]DLL 2025-03-10 09:50:42.847781 - 13 reduced_train_loss : 4.206851959228516  lr : 2.79441110251355e-06  global_step : 13.0  consumed_samples : 14336.0  train_backward_timing in s : 4.572868347167969e-05  grad_norm : 24.091997146606445  train_step_timing in s : 25.607507514953614  epoch : 0 
Epoch 0: 100% 15/15 [06:30<00:00, 26.02s/it, v_num=None, reduced_train_loss=4.210, global_step=13.00, consumed_samples=14336.0, traiEpoch 0: 100% 15/15 [06:30<00:00, 26.02s/it, v_num=None, reduced_train_loss=3.220, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=25.60]DLL 2025-03-10 09:51:08.441068 - 14 reduced_train_loss : 3.2204487323760986  lr : 2.994011992996093e-06  global_step : 14.0  consumed_samples : 15360.0  train_backward_timing in s : 4.3392181396484375e-05  grad_norm : 20.592880249023438  train_step_timing in s : 25.60191674232483  epoch : 0 
Epoch 0: 100% 15/15 [06:30<00:00, 26.02s/it, v_num=None, reduced_train_loss=3.220, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=25.60]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [06:30<00:00, 26.02s/it, v_num=None, reduced_train_loss=3.220, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=25.60]
[NeMo I 2025-03-10 09:51:08 nemo_logging:393] train_step_timing in s: [32.49, 28.88, 27.74, 27.19, 26.86, 25.48, 25.54, 25.57, 25.59, 25.6, 25.61, 25.61, 25.6, 25.61, 25.6]
[NeMo I 2025-03-10 09:51:08 nemo_logging:393] TFLOPs per sec per GPU=1186.11