Epoch 0:   7% 1/15 [00:29<06:51, 29.41s/it, v_num=None, reduced_train_loss=11.00, global_step=0.000, consumed_samples=1024.0, train_step_timing in s=29.40]DLL 2025-03-09 11:02:32.250171 - 0 reduced_train_loss : 11.027783393859863  lr : 1.9960080521741475e-07  global_step : 0.0  consumed_samples : 1024.0  train_backward_timing in s : 4.315376281738281e-05  grad_norm : 11.146327018737793  train_step_timing in s : 29.407729625701904  epoch : 0 
Epoch 0:  13% 2/15 [00:48<05:16, 24.38s/it, v_num=None, reduced_train_loss=11.00, global_step=1.000, consumed_samples=2048.0, train_step_timing in s=24.40]DLL 2025-03-09 11:02:51.606294 - 1 reduced_train_loss : 11.027694702148438  lr : 3.992016104348295e-07  global_step : 1.0  consumed_samples : 2048.0  train_backward_timing in s : 4.124641418457031e-05  grad_norm : 12.122929573059082  train_step_timing in s : 24.380370020866394  epoch : 0 
Epoch 0:  20% 3/15 [01:08<04:32, 22.69s/it, v_num=None, reduced_train_loss=10.30, global_step=2.000, consumed_samples=3072.0, train_step_timing in s=22.70]DLL 2025-03-09 11:03:10.923786 - 2 reduced_train_loss : 10.270742416381836  lr : 5.988023872305348e-07  global_step : 2.0  consumed_samples : 3072.0  train_backward_timing in s : 4.1484832763671875e-05  grad_norm : 13.100915908813477  train_step_timing in s : 22.691771904627483  epoch : 0 
Epoch 0:  27% 4/15 [01:27<04:00, 21.88s/it, v_num=None, reduced_train_loss=10.20, global_step=3.000, consumed_samples=4096.0, train_step_timing in s=21.90]DLL 2025-03-09 11:03:30.354468 - 3 reduced_train_loss : 10.179738998413086  lr : 7.98403220869659e-07  global_step : 3.0  consumed_samples : 4096.0  train_backward_timing in s : 4.1425228118896484e-05  grad_norm : 13.31692123413086  train_step_timing in s : 21.8757563829422  epoch : 0 
Epoch 0:  33% 5/15 [01:46<03:33, 21.39s/it, v_num=None, reduced_train_loss=10.00, global_step=4.000, consumed_samples=5120.0, train_step_timing in s=21.40]DLL 2025-03-09 11:03:49.812657 - 4 reduced_train_loss : 10.039163589477539  lr : 9.980039976653643e-07  global_step : 4.0  consumed_samples : 5120.0  train_backward_timing in s : 4.253387451171875e-05  grad_norm : 13.860750198364258  train_step_timing in s : 21.39169034957886  epoch : 0 
Epoch 0:  40% 6/15 [02:06<03:09, 21.08s/it, v_num=None, reduced_train_loss=9.860, global_step=5.000, consumed_samples=6144.0, train_step_timing in s=19.40]DLL 2025-03-09 11:04:09.309708 - 5 reduced_train_loss : 9.860638618469238  lr : 1.1976047744610696e-06  global_step : 5.0  consumed_samples : 6144.0  train_backward_timing in s : 4.420280456542969e-05  grad_norm : 14.449723243713379  train_step_timing in s : 19.40898690223694  epoch : 0 
Epoch 0:  47% 7/15 [02:25<02:46, 20.86s/it, v_num=None, reduced_train_loss=9.660, global_step=6.000, consumed_samples=7168.0, train_step_timing in s=19.40]DLL 2025-03-09 11:04:28.826350 - 6 reduced_train_loss : 9.663114547729492  lr : 1.397205551256775e-06  global_step : 6.0  consumed_samples : 7168.0  train_backward_timing in s : 4.46319580078125e-05  grad_norm : 14.887728691101074  train_step_timing in s : 19.44111795425415  epoch : 0 
Epoch 0:  53% 8/15 [02:45<02:24, 20.68s/it, v_num=None, reduced_train_loss=9.410, global_step=7.000, consumed_samples=8192.0, train_step_timing in s=19.50]DLL 2025-03-09 11:04:48.315371 - 7 reduced_train_loss : 9.4080810546875  lr : 1.596806441739318e-06  global_step : 7.0  consumed_samples : 8192.0  train_backward_timing in s : 4.4298171997070315e-05  grad_norm : 15.631380081176758  train_step_timing in s : 19.475407457351686  epoch : 0 
Epoch 0:  60% 9/15 [03:04<02:03, 20.55s/it, v_num=None, reduced_train_loss=9.110, global_step=8.000, consumed_samples=9216.0, train_step_timing in s=19.50]DLL 2025-03-09 11:05:07.827028 - 8 reduced_train_loss : 9.110034942626953  lr : 1.7964072185350233e-06  global_step : 8.0  consumed_samples : 9216.0  train_backward_timing in s : 4.4298171997070315e-05  grad_norm : 16.30112648010254  train_step_timing in s : 19.49158821105957  epoch : 0 
Epoch 0:  67% 10/15 [03:24<01:42, 20.45s/it, v_num=None, reduced_train_loss=8.790, global_step=9.000, consumed_samples=10240.0, train_step_timing in s=19.50]DLL 2025-03-09 11:05:27.361411 - 9 reduced_train_loss : 8.786163330078125  lr : 1.9960079953307286e-06  global_step : 9.0  consumed_samples : 10240.0  train_backward_timing in s : 4.572868347167969e-05  grad_norm : 17.199861526489258  train_step_timing in s : 19.506804752349854  epoch : 0 
Epoch 0:  73% 11/15 [03:44<01:21, 20.37s/it, v_num=None, reduced_train_loss=8.350, global_step=10.00, consumed_samples=11264.0, train_step_timing in s=19.50]DLL 2025-03-09 11:05:46.879091 - 10 reduced_train_loss : 8.348357200622559  lr : 2.1956088858132716e-06  global_step : 10.0  consumed_samples : 11264.0  train_backward_timing in s : 4.353523254394531e-05  grad_norm : 18.400270462036133  train_step_timing in s : 19.51084961891174  epoch : 0 
Epoch 0:  80% 12/15 [04:03<01:00, 20.30s/it, v_num=None, reduced_train_loss=7.940, global_step=11.00, consumed_samples=12288.0, train_step_timing in s=19.50]DLL 2025-03-09 11:06:06.433050 - 11 reduced_train_loss : 7.937857627868652  lr : 2.3952095489221392e-06  global_step : 11.0  consumed_samples : 12288.0  train_backward_timing in s : 4.3058395385742186e-05  grad_norm : 18.82196044921875  train_step_timing in s : 19.51834282875061  epoch : 0 
Epoch 0:  87% 13/15 [04:23<00:40, 20.24s/it, v_num=None, reduced_train_loss=7.410, global_step=12.00, consumed_samples=13312.0, train_step_timing in s=19.50]DLL 2025-03-09 11:06:25.964250 - 12 reduced_train_loss : 7.409639835357666  lr : 2.5948104394046823e-06  global_step : 12.0  consumed_samples : 13312.0  train_backward_timing in s : 4.224777221679687e-05  grad_norm : 19.854900360107422  train_step_timing in s : 19.52679877281189  epoch : 0 
Epoch 0:  93% 14/15 [04:42<00:20, 20.19s/it, v_num=None, reduced_train_loss=6.860, global_step=13.00, consumed_samples=14336.0, train_step_timing in s=19.50]DLL 2025-03-09 11:06:45.502662 - 13 reduced_train_loss : 6.86191463470459  lr : 2.79441110251355e-06  global_step : 13.0  consumed_samples : 14336.0  train_backward_timing in s : 4.124641418457031e-05  grad_norm : 20.701583862304688  train_step_timing in s : 19.53218584060669  epoch : 0 
Epoch 0: 100% 15/15 [05:02<00:00, 20.15s/it, v_num=None, reduced_train_loss=6.210, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=19.50]DLL 2025-03-09 11:07:05.028821 - 14 reduced_train_loss : 6.212850570678711  lr : 2.994011992996093e-06  global_step : 14.0  consumed_samples : 15360.0  train_backward_timing in s : 3.8623809814453125e-05  grad_norm : 22.090660095214844  train_step_timing in s : 19.53054013252258  epoch : 0 
Epoch 0: 100% 15/15 [05:02<00:00, 20.15s/it, v_num=None, reduced_train_loss=6.210, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=19.50]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [05:02<00:00, 20.15s/it, v_num=None, reduced_train_loss=6.210, global_step=14.00, consumed_samples=15360.0, train_step_timing in s=19.50]
[NeMo I 2025-03-09 11:07:05 nemo_logging:393] train_step_timing in s: [29.41, 24.38, 22.69, 21.88, 21.39, 19.41, 19.44, 19.48, 19.49, 19.51, 19.51, 19.52, 19.53, 19.53, 19.53]
[NeMo I 2025-03-09 11:07:05 nemo_logging:393] TFLOPs per sec per GPU=1556.08