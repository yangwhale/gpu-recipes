Epoch 0:   7% 1/15 [00:25<06:02, 25.88s/it, v_num=None, reduced_train_loss=11.20, global_step=0.000, consumed_samples=64.00, train_step_timing in s=25.90]DLL 2025-03-10 02:29:24.367739 - 0 reduced_train_loss : 11.168447494506836  lr : 0.0  global_step : 0.0  consumed_samples : 64.0  train_backward_timing in s : 4.482269287109375e-05  grad_norm : 43.194026947021484  train_step_timing in s : 25.87619185447693  epoch : 0 
Epoch 0:  13% 2/15 [00:41<04:29, 20.70s/it, v_num=None, reduced_train_loss=11.20, global_step=1.000, consumed_samples=128.0, train_step_timing in s=20.70]DLL 2025-03-10 02:29:39.893897 - 1 reduced_train_loss : 11.169539451599121  lr : 7.500000265281415e-08  global_step : 1.0  consumed_samples : 128.0  train_backward_timing in s : 4.780292510986328e-05  grad_norm : 46.24556350708008  train_step_timing in s : 20.699687957763672  epoch : 0 
Epoch 0:  20% 3/15 [00:56<03:45, 18.79s/it, v_num=None, reduced_train_loss=11.00, global_step=2.000, consumed_samples=192.0, train_step_timing in s=18.80]DLL 2025-03-10 02:29:54.871554 - 2 reduced_train_loss : 11.048635482788086  lr : 1.500000053056283e-07  global_step : 2.0  consumed_samples : 192.0  train_backward_timing in s : 4.80810801188151e-05  grad_norm : 42.8829231262207  train_step_timing in s : 18.791242758433025  epoch : 0 
Epoch 0:  27% 4/15 [01:11<03:16, 17.85s/it, v_num=None, reduced_train_loss=10.80, global_step=3.000, consumed_samples=256.0, train_step_timing in s=17.80]DLL 2025-03-10 02:30:09.897652 - 3 reduced_train_loss : 10.785797119140625  lr : 2.2499999374758772e-07  global_step : 3.0  consumed_samples : 256.0  train_backward_timing in s : 4.935264587402344e-05  grad_norm : 42.978271484375  train_step_timing in s : 17.84916752576828  epoch : 0 
Epoch 0:  33% 5/15 [01:26<02:52, 17.30s/it, v_num=None, reduced_train_loss=10.40, global_step=4.000, consumed_samples=320.0, train_step_timing in s=17.30]DLL 2025-03-10 02:30:24.973785 - 4 reduced_train_loss : 10.38028621673584  lr : 3.000000106112566e-07  global_step : 4.0  consumed_samples : 320.0  train_backward_timing in s : 4.8828125e-05  grad_norm : 44.71546173095703  train_step_timing in s : 17.293952798843385  epoch : 0 
Epoch 0:  40% 6/15 [01:41<02:32, 16.92s/it, v_num=None, reduced_train_loss=9.850, global_step=5.000, consumed_samples=384.0, train_step_timing in s=15.10]DLL 2025-03-10 02:30:39.987903 - 5 reduced_train_loss : 9.852010726928711  lr : 3.7500001326407073e-07  global_step : 5.0  consumed_samples : 384.0  train_backward_timing in s : 4.7540664672851564e-05  grad_norm : 46.82932662963867  train_step_timing in s : 15.120901679992675  epoch : 0 
Epoch 0:  47% 7/15 [01:56<02:13, 16.65s/it, v_num=None, reduced_train_loss=9.170, global_step=6.000, consumed_samples=448.0, train_step_timing in s=15.00]DLL 2025-03-10 02:30:55.056165 - 6 reduced_train_loss : 9.171876907348633  lr : 4.4999998749517545e-07  global_step : 6.0  consumed_samples : 448.0  train_backward_timing in s : 4.701614379882812e-05  grad_norm : 52.069488525390625  train_step_timing in s : 15.029258728027344  epoch : 0 
Epoch 0:  53% 8/15 [02:11<01:55, 16.46s/it, v_num=None, reduced_train_loss=8.480, global_step=7.000, consumed_samples=512.0, train_step_timing in s=15.10]DLL 2025-03-10 02:31:10.151630 - 7 reduced_train_loss : 8.484909057617188  lr : 5.25000018569699e-07  global_step : 7.0  consumed_samples : 512.0  train_backward_timing in s : 4.744529724121094e-05  grad_norm : 54.982513427734375  train_step_timing in s : 15.05282211303711  epoch : 0 
Epoch 0:  60% 9/15 [02:26<01:37, 16.31s/it, v_num=None, reduced_train_loss=7.450, global_step=8.000, consumed_samples=576.0, train_step_timing in s=15.10]DLL 2025-03-10 02:31:25.258836 - 8 reduced_train_loss : 7.445510387420654  lr : 6.000000212225132e-07  global_step : 8.0  consumed_samples : 576.0  train_backward_timing in s : 4.5347213745117185e-05  grad_norm : 64.67536163330078  train_step_timing in s : 15.06899127960205  epoch : 0 
Epoch 0:  67% 10/15 [02:41<01:20, 16.18s/it, v_num=None, reduced_train_loss=6.370, global_step=9.000, consumed_samples=640.0, train_step_timing in s=15.10]DLL 2025-03-10 02:31:40.302895 - 9 reduced_train_loss : 6.373483180999756  lr : 6.750000238753273e-07  global_step : 9.0  consumed_samples : 640.0  train_backward_timing in s : 4.405975341796875e-05  grad_norm : 69.76773071289062  train_step_timing in s : 15.062613725662231  epoch : 0 
Epoch 0:  73% 11/15 [02:56<01:04, 16.08s/it, v_num=None, reduced_train_loss=5.320, global_step=10.00, consumed_samples=704.0, train_step_timing in s=15.10]DLL 2025-03-10 02:31:55.319503 - 10 reduced_train_loss : 5.319241523742676  lr : 7.500000265281415e-07  global_step : 10.0  consumed_samples : 704.0  train_backward_timing in s : 4.425048828125e-05  grad_norm : 72.19927215576172  train_step_timing in s : 15.063147258758544  epoch : 0 
Epoch 0:  80% 12/15 [03:11<00:47, 15.99s/it, v_num=None, reduced_train_loss=4.330, global_step=11.00, consumed_samples=768.0, train_step_timing in s=15.10]DLL 2025-03-10 02:32:10.408027 - 11 reduced_train_loss : 4.331667900085449  lr : 8.249999723375367e-07  global_step : 11.0  consumed_samples : 768.0  train_backward_timing in s : 4.553794860839844e-05  grad_norm : 66.52930450439453  train_step_timing in s : 15.06730251312256  epoch : 0 
Epoch 0:  87% 13/15 [03:26<00:31, 15.92s/it, v_num=None, reduced_train_loss=3.430, global_step=12.00, consumed_samples=832.0, train_step_timing in s=15.10]DLL 2025-03-10 02:32:25.467839 - 12 reduced_train_loss : 3.42962908744812  lr : 8.999999749903509e-07  global_step : 12.0  consumed_samples : 832.0  train_backward_timing in s : 4.3487548828125e-05  grad_norm : 56.98670959472656  train_step_timing in s : 15.060255241394042  epoch : 0 
Epoch 0:  93% 14/15 [03:42<00:15, 15.86s/it, v_num=None, reduced_train_loss=2.700, global_step=13.00, consumed_samples=896.0, train_step_timing in s=15.10]DLL 2025-03-10 02:32:40.539375 - 13 reduced_train_loss : 2.7009990215301514  lr : 9.75000034486584e-07  global_step : 13.0  consumed_samples : 896.0  train_backward_timing in s : 4.2772293090820314e-05  grad_norm : 46.1029052734375  train_step_timing in s : 15.053192472457885  epoch : 0 
Epoch 0: 100% 15/15 [03:57<00:00, 15.81s/it, v_num=None, reduced_train_loss=2.180, global_step=14.00, consumed_samples=960.0, train_step_timing in s=15.10]DLL 2025-03-10 02:32:55.616208 - 14 reduced_train_loss : 2.1794137954711914  lr : 1.050000037139398e-06  global_step : 14.0  consumed_samples : 960.0  train_backward_timing in s : 4.5251846313476565e-05  grad_norm : 36.62604904174805  train_step_timing in s : 15.059717750549316  epoch : 0 
Epoch 0: 100% 15/15 [03:57<00:00, 15.81s/it, v_num=None, reduced_train_loss=2.180, global_step=14.00, consumed_samples=960.0, train_step_timing in s=15.10]`Trainer.fit` stopped: `max_steps=15` reached.
Epoch 0: 100% 15/15 [03:57<00:00, 15.81s/it, v_num=None, reduced_train_loss=2.180, global_step=14.00, consumed_samples=960.0, train_step_timing in s=15.10]
[NeMo I 2025-03-10 02:32:55 nemo_logging:393] train_step_timing in s: [25.88, 20.7, 18.79, 17.85, 17.29, 15.12, 15.03, 15.05, 15.07, 15.06, 15.06, 15.07, 15.06, 15.05, 15.06]
[NeMo I 2025-03-10 02:32:55 nemo_logging:393] TFLOPs per sec per GPU=1047.52